% Comando simples para exibir comandos Latex no texto
\newcommand{\comando}[1]{\textbf{$\backslash$#1}}


Técnicas de \textit{Machine Learning} estão sendo utilizadas cada vez mais na indústria e ciência com o principal objetivo de obter informações através dos dados. O aumento do uso dessas técnicas se deve ao volume cada vez maior de dados sendo produzidos, bem como o aumento na performance para processar esses dados e a redução de custos para armazená-los. Os modelos de \textit{machine learning} estão sendo usados em diversas áreas da ciência, desde o diagnóstico de algumas doenças pelo reconhecimento de imagens em laboratórios médicos até o reconhecimento de padrões e comportamentos com o objetivo de mapear consumidores e facilitar a tomada de decisão para a venda ou recomendação de algum produto. Com esse forte crescimento, a pesquisa na área teórica e na aplicação de técnicas de \textit{machine learning} vem se se destacando, mostrando a importância de um modelo robusto de \textit{machine learning} para as aplicações científica e industrial.

\textit{Gradient Boosting Machines} (GBMs) vem obtendo resultados no estado da arte, principalmente em casos de dados estruturados, ou seja, dados que possuem um padrão bem definido. Por exemplo: dados organizados através de linhas e colunas, onde não é permitido dados diferentes das estruturas preestabelecidas. Se a coluna de uma tabela foi criada para ser numérica, ela não aceitará outro tipo de dados. Em uma pesquisa feita pela plataforma Kaggle,\textit{State of Data Science and Machine Learning 2022} \cite{kaggle}, GBMs como XGBoost, LightGBM e CatBoost estão entre os algoritmos mais utilizado pelos respondentes da pesquisa. Esses algoritmos são baseados em árvore de decisão e utilizam uma estrutura de \textit{Gradient boosting} para aumentar a performance do modelo.

Além da escolha do melhor algoritmo para construir o seu modelo de \textit{Machine Learning} temos o desafio de escolher os hiperparâmetros para o treino do modelo. Eles são de extrema importância pois são atributos que controlam o treinamento do modelo de \textit{machine learning}. Eles previnem o modelo de aprender apenas com os dados mostrados,  ou seja, previnem \textit{overfitting} e \textit{underfitting}, tornando-o capaz de generalizar para outras situações possíveis. Nas implementações mencionadas -- XGboost, LightGBM e CatBoost -- todos os hiperparâmetros costumam ter valores pré-estabelecidos. Encontrar os melhores hiperparâmetros é uma tarefa extremamente desafiadora na área de \textit{Machine Learning}. Após o comparativo dos modelos de \textit{boosting}, o melhor modelo será escolhido para utilizar uma ferramenta de automatização de hiperparâmetros, o Optuna. Assim, podemos avaliar se apenas o ajuste dos hiperparâmetros é capaz de melhorar o resultado do modelo treinado.

Neste capítulo será abordada a revisão bibliográfica sobre o tema aprendizado de máquina e o embasamento teórico do problema de classificação. Também serão apresentadas as características do conjunto de dados, explicando o conceito de cada variável e a distinção entre variáveis explicativas e variável resposta.

\section{Conceitos Iniciais}
Diversos autores definem aprendizagem como a capacidade de um programa computacional conseguir melhorar seu desempenho através do aprendizado \cite{hastie} \cite{mitchell}, tornando suas ações mais precisas \cite{marsland} ou inferir regras gerais através da observação de exemplos \cite{luxburg:artigo}. Ou seja, a partir de algoritmos de aprendizagem  o computador consegue aprender tarefas específicas. O conceito chave para as máquinas é essa aprendizagem a partir dos dados e que com isso a máquina consiga generalizar, definida como a identificação
de similaridade entre diferentes situações, é o que torna a aprendizagem útil, pois o conhecimento adquirido pode ser aplicado em diversos cenários. 

\subsection{Aprendizado de Máquina}
O aprendizado de máquina mescla ideias da matemática, física, neurociência e biologia. Segundo estes autores, o aprendizado de máquina, diferente da inteligência artificial, não procura gerar um comportamento inteligente, mas descobrir mecanismos através dos quais tarefas específicas podem ser aprendidas por computadores, ou seja com o foco na capacidade de generalização \cite{hastie} \cite{marsland}.
O aprendizado de máquina tem origens na estatística, ciência da computação e inteligencia artificial e agora estabeleceu-se como uma disciplina por direito próprio \cite{luxburg:artigo}.

De maneira geral os problemas de aprendizado podem ser classificados como:
\begin{itemize}
  \item \textbf{Aprendizado Supervisionado:} um conjunto de respostas corretas é fornecido para esse aprendizado de tal forma que o algoritmo escolhido consiga generalizar para responder corretamente as possíveis novas entradas. Alguns algoritimos são ,por exemplo, regressão linear, análise de regressão logística, \textit{K-Nearest Neighbors}, S\textit{upport Vector Machines}, \textit{Random Forests} e Árvores de Decisão.
  \item \textbf{Aprendizado Não Supervisionado:} o conjunto de respostas corretas não é fornecido para o algoritmo e, portando, o algoritmo procura identificar padrões ou similaridades entre os objetos de entrada para que eles apresentem algo em comum e que seja possível agrupá-los. Nesse aprendizado, busca-se encontrar o padrão entre as diferentes amostras e separar as que possuem as mesmas características. Um exemplo desse aprendizado são os algorítimos de clusterização que tem como objetivo agrupamento dos dados que possuem características semelhantes, por exemplo, \textit{K-Means}, DBSCAN e \textit{Hierarchical Cluster Analysis} (HCA). 
  \item \textbf{Aprendizado Por Reforço:} O sistema de aprendizado, que nesse contexto receberá o nome de agente, é treinado para tomar uma sequência de decisões. Nesse tipo de aprendizado o agente executa alguma ação e recebe recompensas ou penalidades em troca. Seu objetivo é ser capaz de tomar as melhores decisões para obter o maior número de recompensas ao longo do tempo, usando testes totalmente aleatórios no início e obtendo a melhor solução ao final. Diferente dos outros, este aprendizado não precisa de dados rotulados para tomar a sua ação. Alguns algoritmos são, por exemplo, Processo de Decisão de Markov, \textit{Q-Learning}, Monte Carlo, \textit{Deep Q-Learning} e \textit{Deep Deterministic Policy Gradient}.
\end{itemize}
\subsection{Problema de Classificação}
Em um problema de classificação temos dois tipos de espaço para ser considerado, conforme abordado em \cite{luxburg:artigo}, temos o espaço $X$ das instancias ou objetos e o espaço $Y$ das saídas ou categorias. No caso que será abordado neste trablaho, a classificação binária, o espaço de saídas é um indicador booleano dado pelo conjunto ${(0,+1)}$  -- em alguns casos podemos ter o conjunto ${(-1,+1)}$. O objetivo é encontrar um mapeamento $f:X \rightarrow Y$ chamado de classificador. Um algoritmo de classificação, portanto, é um procedimento que toma como entrada os exemplos de treinamento e produz como saída um classificador $f$. Este tópico será abordado com maiores detalhes no Capítulo \ref{chapter:fundamentos-aprendizado}.

De maneira geral, os tópicos que descrevem os processos para resolver um problema de aprendizado supervisionado se resumem em \cite{hastie} \cite{marsland}:

\begin{enumerate}
\item \textbf{Coleta e preparação dos dados:} os dados precisam ser coletados e tratados antes de colocar no treino do modelo. É preciso fazer uma análise estatística do conjunto de dados e realizar os tratamentos necessários para os dados faltantes e/ou \textit{outliers}.
\item \textbf{Seleção de variáveis:} requer o conhecimento prévio do problema e dos dados coletados para identificar quais variáveis podem ser úteis para resolver o problema e, se necessário, criar novas variáveis a partir das existentes ou até aplicar redução de dimensionalidade nas variáveis.
\item \textbf{Escolha do algoritmo:} definidos o problema e o conjunto de dados, um ou mais algoritmos de aprendizado de máquina são selecionados.
\item \textbf{Determinação dos parâmetros:} alguns algoritmos necessitam que alguns parametros sejam colocados manualmente, por exemplo, número de interações, tolerância ao erro, tamanho da amostra, etc.
\item \textbf{Determinação dos Hiperparâmetros:} são parâmetros que definem a arquitetura de um método de aprendizado. Enquanto os parâmetros do modelo especificam como transformar os objetos de entrada na saída desejada, os hiperparâmetros definem como o modelo é realmente estruturado. Os hiperparâmetros não podem ser estimados diretamente do conjunto de treinamento. Alguns exemplos de hiperparâmetros são taxa de aprendizado, número de épocas, número de galhos e folhas em uma árvore de decisão, profundidade máxima da folha, etc.
\item \textbf{Treinamento:} com os dados e os algorítimos essa etapa consiste no uso computacional a fim de construir uma função $\hat{f}(x)$ que tem como objetivo prever as saídas a partir de novos dados.
\item \textbf{Validação:} esta etapa inclui a seleção de métricas para avaliação de desempenho do modelo construído, neste caso um classificador. São utilizados dados que não foram usados no conjunto de treinamento do modelo.
\item \textbf{Tuning do Modelo:} esta etapa consiste em melhorar a performance do modelo apenas alterando os parâmetros e/ou hiperparâmetros. É um processo complexo que é utilizado para melhorar a performance dos modelos treinados. Consiste em realizar diversos treinos alterando os hiperparâmetros de forma sistemática e, no final, escolher o modelo com a melhor métrica de performance.
\item \textbf{Predições:} com o modelo finalizado, fazer as predições significa fornecer a ele dados novos e obter as saídas. Essa é a última etapa da resolução de um problema de aprendizado supervisionado, onde podemos concluir que o problema foi resolvido. 
\end{enumerate}
\subsection{Variáveis e Conjunto de Dados}
O conjunto de dados é representado por um vetor de características que descreve as observações. As variáveis são mensuradas em cada elemento da amostra ou população que apresentam características diferentes de indíviduo para indivíduo. 
Quando qualquer medição de uma caracteristica está ausente, dizemos que aquele valor é \textit{missing}. Cada observação, também denominada objeto ou registro, corresponde a uma ocorrência dos dados e cada variável está associada a uma propriedade específica dos objetos, podendo esta propriedade retratar noções físicas ou abstratas. Uma coleção de observações assim constituídas compõe um conjunto de dados. 
As variáveis podem assumir valores numéricos e não numéricos, podemos classifica-las em:

\begin{itemize}
    \item \textbf{Numéricas ou quantitativas:}
    \begin{enumerate}
        \item \textbf{Contínuas:} são variáveis mensuráveis que se originam de algum processo de medição e que podem assumir qualquer valor em uma escala contínua seja $x_i$\simbolo{x_i}{o exemplo i-enésimo de um conjunto de dados, vetor ou escalar} para uma variável contínua temos que $x_i\in\mathbb{R}$ \simbolo{\mathbb{R}}{Conjunto dos números reais}.Exemplos: salário, pressão arterial, altura e etc.
        \item \textbf{Discretas:} são variáveis que são originadas de um processo de contagem, que podem assumir um número finito ou infinito contável de valores. Seja $x_i$ uma variável discreta, temos que $x_i\in\mathbb{Z}$\simbolo{\mathbb{Z}}{Conjunto dos números inteiros}. Exemplos: número de filhos, quantidade de quartos em uma casa e etc.
    \end{enumerate}
    \item \textbf{Categóricas ou qualitativas:}
        \begin{enumerate}
        \item \textbf{Ordinal:} os valores apresentam uma ordem definida e é possível determinar qual é o maior valor e o menor valor. Por exemplo: escolaridade, \textit{rating} de risco de um país, meses do ano, nota de um teste e etc.
        \item \textbf{Nominal:} os valores não apresentam uma ordem definida são penas nomes diferentes que representam alguma característica. Por exemplo: sexo, cor dos olhos, profissão, religião e etc.
    \end{enumerate}
\end{itemize}
Os conjuntos de dados apresentam atributos de entrada, também denominados \textbf{variáveis
explicativas, preditoras ou independentes}, e podem apresentar um atributo alvo, também chamado de \textit{target}, \textbf{variável resposta ou variável dependente}, que representa o evento que queremos realizar as nossas previsões. Nos problemas de regressão, a varíavel resposta contém valores númericos contínuos enquanto que, nos problemas de classificação, o atributo alvo é uma variável discreta, geralmente um indicador booleano $(0,1)$.

Um conjunto de dados é representado por uma matriz de objetos $X_{n\times d}$ em que $n$ é o número de objetos e $d$ é o número de atributos de entrada. Este valor define a dimensão da base de dados e cada elemento $x_{ij}$ da matriz contém o valor da $j$-ésima característica para o $i$-ésmo objeto com $j=1,2,3,...,d$ e $i=1,2,3,...,n$. De maneira análoga, a $i$-ésima observação da variável resposta é representada por $y_i$.
\section{Objetivos}
O principal objetivo desse trabalho é o estudo dos três algorítimos de \textit{boosting} XGboost, LGBM e CatBoost em um problema de classificação binária, comparando a performance e o custo computacional (tempo de execução) de cada algoritmo em diferentes \textit{datasets}. Também é feita uma análise dos hiperparâmetros em cada uma das implementações, avaliando como eles afetam o resultado final dos modelos. E por fim, os hiperparâmetros do LGBM são otimizados utilizando o Optuna, um framework Open Source voltado para automatizar a busca pelos melhores hiperparâmetros. Podemos sumarizar o estudo deste trabalho nos seguintes pontos:
\begin{enumerate}
   \item Quais as principais diferenças de cada algoritmo? O conjunto de dados afeta o resultado final em cada algoritmo ? Qual o algoritmo que obteve a melhor performance tanto do ponto de vista computacional e na métrica de validação ?
   \item Como os hiperparâmetros afetam o treino do modelo? 
   \item Como funciona o Optuna? Após a aplicação do Optuna, conseguimos melhorar a métrica de validação do modelo?
\end{enumerate}

\section{Descrições dos Capítulos}
Nos próximos dois capítulos, \autoref{chapter:fundamentos-aprendizado} e \autoref{chapter:algoritmos-boosting} serão introduzidos os fundamentos teóricos para o aprendizado supervisionado, as métricas de validações, os algoritmos de boosting e o que são hiperparâmetros. No \autoref{chapter:desenvolvimento} temos as implementações das funções dos algoritmos e do optuna, de tal forma que o experimento fique replicável e comparável entre os algoritmos. Além disso, discriminamos a estrutura dos testes realizados. No \autoref{chapter:experimental}, temos o resultado dos testes implementados no \autoref{chapter:desenvolvimento}, além de uma análise estatística dos conjuntos de dados utilizados. Buscamos ainda interpretar quais variáveis impactam o modelo. No \autoref{chapter:resultados} será abordada a análise final, comparando os trés algoritmos, suas métricas de validação, de performance e custo computacional. Em seguida, teremos a análise de alguns hiperparâmetros e, por final, o modelo otimizado pelo Optuna e sua performance. Culminamos no \autoref{chapter:conclusao}, onde teremos a conclusão final de todo o trabalho realizado neste estudo, uma análise das limitações do mesmo, bem como sugestões de trabalhos futuros.

Nos apêndices, se encontram os materiais complementares que contém inclusive o Jupyter Notebook, com os códigos implementados. Há também a  referência da página no \textit{GitHub}, onde o código fonte final deste trabalho está disponibilizado. 
